{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPPu1GIpH4Tu+DdIp5LPrMm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinwooChoi/ESAA-OB/blob/main/11_07_ESAA_OB_%ED%95%84%EC%82%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "범위: <딥러닝 파이토치 교과서> 1-2장 p.18-60"
      ],
      "metadata": {
        "id": "0tX0CFZLX_Qi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 인공지능, 머신러닝, 딥러닝\n",
        "\n",
        "#### 인공지능(AI)\n",
        "- 인간의 지능을 모방하여 컴퓨터가 인간의 일을 수행할 수 있도록 하는 기술  \n",
        "- 구현 방법: **머신러닝(Machine Learning)**, **딥러닝(Deep Learning)**  \n",
        "\n",
        "#### 계층적 관계\n",
        "> 인공지능 ＞ 머신러닝 ＞ 딥러닝  \n",
        "\n",
        "- AI(전체 개념)  \n",
        "- ML(AI를 구현하는 방법)  \n",
        "- DL(ML의 세부 영역, 신경망 기반)  \n",
        "\n",
        "#### 머신러닝 vs 딥러닝\n",
        "| 구분 | 머신러닝 | 딥러닝 |\n",
        "|------|-----------|---------|\n",
        "| **동작 원리** | 입력 데이터에 알고리즘 적용해 예측 수행 | 신경망을 사용해 데이터의 특징·관계 해석 |\n",
        "| **재사용** | 동일한 유형의 데이터 재사용 어려움 | 학습된 모델로 다양한 데이터 재사용 가능 |\n",
        "| **데이터 규모** | 수천 개 수준 필요 | 수백만 개 이상 필요 |\n",
        "| **훈련 시간** | 단시간 | 장시간 |\n",
        "| **결과 형태** | 수치(점수·분류) | 이미지, 텍스트, 소리 등 다양한 형태 |\n",
        "\n",
        "#### 머신러닝과 딥러닝의 차이\n",
        "- **머신러닝** : 사람이 데이터를 전처리 후 컴퓨터가 학습  \n",
        "- **딥러닝** : 컴퓨터가 스스로 데이터 특징을 추출·학습  \n",
        "\n",
        "### 1.2 머신러닝이란\n",
        "\n",
        "#### 정의\n",
        "- 인공지능의 한 분야로, **컴퓨터가 데이터에서 학습하여 스스로 예측·판단하는 기술**\n",
        "\n",
        "#### 머신러닝 학습 과정\n",
        "- 주요 단계: **데이터 입력 → 특징 추출 → 모델 학습 → 예측 결과**\n",
        "- **훈련(train)** : 주어진 데이터로 모델을 학습  \n",
        "- **테스트(test)** : 새로운 데이터로 모델의 예측 성능 평가  \n",
        "\n",
        "#### 머신러닝 구성요소\n",
        "- **데이터(Data)** : 입력되는 학습 자료  \n",
        "- **모델(Model)** : 학습 알고리즘  \n",
        "- **평가(Evaluation)** : 정확도·오차율 측정  \n",
        "\n",
        "#### 데이터 구분\n",
        "| 구분 | 설명 |\n",
        "|------|------|\n",
        "| **훈련 데이터(Training)** | 모델 학습용 데이터 |\n",
        "| **검증 데이터(Validation)** | 학습 중 성능 확인용 |\n",
        "| **테스트 데이터(Test)** | 최종 평가용 데이터 |\n",
        "\n",
        "#### 머신러닝 학습 순서\n",
        "1. 모델 구조 설계  \n",
        "2. 데이터 입력 및 학습  \n",
        "3. 평가 후 모델 업데이트  \n",
        "\n",
        "#### 머신러닝의 주요 알고리즘 분류\n",
        "| 구분 | 학습 방식 | 예시 알고리즘 |\n",
        "|------|------------|----------------|\n",
        "| **지도 학습 (Supervised Learning)** | 입력(X)과 정답(Y) 존재 | K-NN, SVM, 선형/로지스틱 회귀 |\n",
        "| **비지도 학습 (Unsupervised Learning)** | 정답 없이 패턴 탐색 | K-평균, DBSCAN 등 군집화 |\n",
        "| **차원 축소 (Dimensionality Reduction)** | 데이터 축소 및 시각화 | PCA, ICA 등 |\n",
        "| **강화 학습 (Reinforcement Learning)** | 보상 기반 행동 학습 | Q-Learning, MDP 등 |\n",
        "\n",
        "#### 지도 학습 (Supervised Learning)\n",
        "- 정답(label)이 있는 데이터를 학습하여 예측  \n",
        "- 예: 입력 7×1=7, 7×2=14 → 7×3 예측  \n",
        "- 회귀(Regression), 분류(Classification) 모두 포함  \n",
        "\n",
        "#### 비지도 학습 (Unsupervised Learning)\n",
        "- 정답이 없는 데이터에서 **패턴·유사도** 탐색  \n",
        "- 예: 데이터 군집화(클러스터링)  \n",
        "\n",
        "#### 강화 학습 (Reinforcement Learning)\n",
        "- **보상(reward)** 을 통해 올바른 행동을 학습  \n",
        "- 반복 시행 → 보상이 큰 행동 선택  \n",
        "- 예: 게임에서 점수·성과를 통해 행동을 개선  \n",
        "\n",
        "### 1.3 딥러닝이란\n",
        "\n",
        "#### 정의\n",
        "- 인간의 신경망 원리를 모방한 인공 신경망 이론 기반의 머신러닝 방법  \n",
        "- 인간의 뇌 뉴런(neuron)과 시냅스(synapse)의 작동 원리를 모델링  \n",
        "\n",
        "#### 뉴런 구성요소\n",
        "- **수상돌기** : 다른 뉴런의 자극을 받아들이는 부분  \n",
        "- **세포체** : 입력 신호를 통합하고 다음 뉴런으로 전달 준비  \n",
        "- **축삭돌기** : 전기 신호를 전달하는 긴 돌기  \n",
        "- **축삭종말** : 다음 뉴런의 수상돌기에 신호 전달  \n",
        "\n",
        "\n",
        "### 1.3.1 딥러닝 학습 과정\n",
        "\n",
        "#### 전체 과정\n",
        "- 머신러닝과 유사하지만 더 복잡한 모델 구조를 사용  \n",
        "- **단계**: 데이터 준비 → 모델 정의 → 모델 학습 → 손실 함수 계산 → 모델 평가  \n",
        "\n",
        "#### 데이터 준비\n",
        "- 학습용 데이터를 구축하는 단계  \n",
        "- 효율적 데이터 준비를 위해 오픈소스 데이터셋(PyTorch, Keras 등)을 활용  \n",
        "\n",
        "#### 모델 정의\n",
        "- 모델의 입력, 은닉, 출력층을 정의  \n",
        "- 층(layer) 개수·활성화 함수·가중치 등을 설정  \n",
        "\n",
        "#### 모델 학습\n",
        "- 학습 데이터를 이용해 손실 최소화  \n",
        "- 손실 함수 예시: **MSE(평균제곱오차)**, **Cross Entropy(교차 엔트로피)**  \n",
        "\n",
        "#### 배치 학습\n",
        "- 데이터를 여러 묶음(batch)으로 나누어 학습  \n",
        "- 예: 데이터 1000개, 배치 크기 20 → 50번 업데이트 진행  \n",
        "\n",
        "#### 모델 평가\n",
        "- 학습된 모델의 성능(performance)을 측정  \n",
        "- 손실이 낮을수록 성능 우수  \n",
        "\n",
        "#### 모델 연결(신경망 구조)\n",
        "- **입력층(Input Layer)** : 데이터 입력  \n",
        "- **은닉층(Hidden Layer)** : 계산 및 특징 추출  \n",
        "- **출력층(Output Layer)** : 최종 결과 도출  \n",
        "\n",
        "#### 역전파(Backpropagation)\n",
        "- 오차를 기반으로 가중치를 업데이트하는 과정  \n",
        "- 파이토치 등의 프레임워크를 통해 자동으로 처리 가능  \n",
        "\n",
        "\n",
        "\n",
        "### 1.3.2 딥러닝 학습 알고리즘\n",
        "\n",
        "#### 종류\n",
        "- 머신러닝과 마찬가지로 **지도 학습**, **비지도 학습**, **강화 학습**으로 구분  \n",
        "\n",
        "#### 주요 알고리즘\n",
        "| 구분 | 알고리즘 | 특징 |\n",
        "|------|-----------|------|\n",
        "| **합성곱 신경망 (CNN)** | 이미지 처리에 특화 | 시각 인식, X-ray, CT 등 |\n",
        "| **순환 신경망 (RNN)** | 시계열 데이터 분석 | 주식, 음성, 텍스트 |\n",
        "| **LSTM** | RNN의 장기 의존성 문제 개선 | 긴 시퀀스 처리 |\n",
        "| **워드 임베딩 (Word2Vec)** | 단어 의미를 벡터로 표현 | 자연어 처리 |\n",
        "| **군집화 (Clustering)** | 유사 데이터 묶기 | 비지도 학습 |\n",
        "| **전이 학습 (Transfer Learning)** | 기존 모델을 재활용 | 소량 데이터로 고성능 모델 구현 |\n",
        "\n",
        "\n",
        "\n",
        "#### 전이 학습(Transfer Learning)\n",
        "- 이미 학습된 모델(Pre-trained Model)을 새로운 데이터에 재사용  \n",
        "- 기존 학습된 지식을 바탕으로 새로운 문제 해결  \n",
        "\n",
        "#### 전이 학습 모델 예시\n",
        "- **VGG**, **Inception**, **MobileNet** 등  \n",
        "- 소량 데이터에서도 빠르고 효율적인 학습 가능  \n",
        "\n",
        "#### 전체 학습 방식 요약\n",
        "| 구분 | 유형 | 대표 알고리즘 |\n",
        "|------|------|----------------|\n",
        "| **지도 학습** | 이미지, 시계열 데이터 | CNN, RNN, ResNet |\n",
        "| **비지도 학습** | 군집화 | K-평균, SOM |\n",
        "| **전이 학습** | 사전 학습 모델 활용 | MobileNetV2 |\n",
        "| **강화 학습** | 보상 기반 행동 학습 | Q-Learning, MDP |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QKi4epW_lYOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 파이토치 개요\n",
        "\n",
        "#### 정의\n",
        "- **PyTorch**는 2017년 공개된 딥러닝 프레임워크로, 파이썬 기반의 동적 계산 그래프를 사용하는 라이브러리  \n",
        "- GPU 가속과 텐서 연산을 지원하여 빠르고 유연한 모델 구축 가능  \n",
        "\n",
        "#### 사용 목적\n",
        "- **딥러닝 연구 개발용** (속도, 효율성 중시)  \n",
        "- **복잡한 수학 연산, GPU 병렬 연산이 필요한 경우**  \n",
        "\n",
        "\n",
        "### 2.1.1 파이토치 특징 및 장점\n",
        "\n",
        "#### 주요 구성요소\n",
        "| 구성요소 | 설명 |\n",
        "|-----------|------|\n",
        "| **GPU** | 병렬 연산 처리, CUDA·cuDNN 통해 고속 계산 가능 |\n",
        "| **텐서(Tensor)** | 파이토치의 기본 데이터 구조, NumPy 배열과 유사 |\n",
        "| **동적 신경망(Define by Run)** | 실행 시점에 그래프 생성, 유연한 디버깅 가능 |\n",
        "\n",
        "#### 장점 요약\n",
        "- GPU 가속 지원으로 빠른 연산 가능  \n",
        "- 직관적 문법으로 디버깅이 용이함  \n",
        "- 계산 그래프를 런타임에 생성 → 직관적인 코드 구조  \n",
        "\n",
        "\n",
        "### 2.1.2 파이토치의 아키텍처\n",
        "\n",
        "#### 구조 개요\n",
        "- **3계층 구조**:  \n",
        "  1. 사용자 API (Python)  \n",
        "  2. 중간 계층 (Autograd, Aten, JIT 등)  \n",
        "  3. 하위 계층 (CUDA, cuDNN 등)\n",
        "\n",
        "#### 주요 패키지 구성\n",
        "| 패키지 | 설명 |\n",
        "|---------|------|\n",
        "| **torch** | 기본 텐서 연산 지원 |\n",
        "| **torch.autograd** | 자동 미분 기능 제공 |\n",
        "| **torch.nn** | 신경망 모듈 정의 및 학습 |\n",
        "| **torch.multiprocessing** | 병렬 연산 지원 |\n",
        "| **torch.utils** | DataLoader 등 유틸리티 포함 |\n",
        "\n",
        "#### 파이토치 엔진\n",
        "- **Autograd C++** : 자동 미분  \n",
        "- **Aten C++** : 텐서 연산  \n",
        "- **JIT C++** : 최적화된 런타임 실행  \n",
        "- **CUDA/cuDNN** : GPU 가속 지원  \n",
        "\n",
        "\n",
        "## 2.2 파이토치 기초 문법\n",
        "\n",
        "### 2.2.1 텐서 다루기\n",
        "\n",
        "#### 텐서 정의\n",
        "- 파이토치의 기본 자료 구조  \n",
        "- NumPy의 ndarray와 유사하지만 **GPU 연산 가능**\n",
        "\n",
        "###2.2.2 데이터 준비\n",
        "데이터 불러오기\n",
        "\n",
        "Pandas 라이브러리를 활용해 CSV, JSON 등 파일을 읽음\n",
        "\n",
        "데이터는 Tensor 형태로 변환해 모델 학습에 사용\n",
        "\n",
        "\n",
        "###2.2.3 모델 정의\n",
        "\n",
        "모델은 계층(layer)으로 구성\n",
        "\n",
        "nn.Module 클래스를 상속받아 사용자 정의 가능\n",
        "\n",
        "\n",
        "### 2.2.4 모델의 파라미터 정의\n",
        "- 손실 함수 (Loss Function)\n",
        "\n",
        "| 함수명                  | 용도    |\n",
        "| -------------------- | ----- |\n",
        "| **BCELoss**          | 이진 분류 |\n",
        "| **CrossEntropyLoss** | 다중 분류 |\n",
        "| **MSELoss**          | 회귀 문제 |\n",
        "\n",
        "- 옵티마이저 (Optimizer)\n",
        "\n",
        "| 메서드                  | 설명       |\n",
        "| -------------------- | -------- |\n",
        "| **optimizer.step()** | 가중치 업데이트 |\n",
        "| **zero_grad()**      | 기울기 초기화  |\n",
        "\n",
        "- 스케줄러 (Scheduler)\n",
        "\n",
        "학습률을 점진적으로 조절하는 기능\n",
        "\n",
        "예: torch.optim.lr_scheduler.StepLR\n",
        "\n",
        "## 2.2.5 모델 훈련\n",
        "\n",
        "#### 개념\n",
        "- 모델의 가중치(파라미터)를 데이터로 학습시키는 과정  \n",
        "- 예: `y = wx + b` 형태에서 `w`, `b`를 최적화  \n",
        "\n",
        "#### 주요 메서드\n",
        "| 메서드 | 설명 |\n",
        "|--------|------|\n",
        "| `optimizer.zero_grad()` | 이전 단계에서 계산된 기울기를 0으로 초기화 |\n",
        "| `loss.backward()` | 손실 함수의 기울기 계산 |\n",
        "| `optimizer.step()` | 계산된 기울기를 바탕으로 가중치 업데이트 |\n",
        "\n",
        "#### 학습 순서 비교\n",
        "| 구분 | 딥러닝 학습 절차 | 파이토치 학습 절차 |\n",
        "|------|------------------|--------------------|\n",
        "| 1 | 모델, 손실함수, 옵티마이저 정의 | 동일 |\n",
        "| 2 | 학습 데이터 반복 처리 | `for`문 사용 |\n",
        "| 3 | 예측 및 손실 계산 | `loss = fn(output, target)` |\n",
        "| 4 | 역전파 수행 | `loss.backward()` |\n",
        "| 5 | 가중치 업데이트 | `optimizer.step()` |\n",
        "\n",
        "\n",
        "\n",
        "### 2.2.6 모델 평가\n",
        "\n",
        "#### 개념\n",
        "- 학습된 모델을 **테스트 데이터**로 평가  \n",
        "- 평가 시 **정확도(accuracy)**, **혼동행렬(confusion matrix)** 등을 사용  \n",
        "\n",
        "\n",
        "###2.2.7 훈련 과정 모니터링\n",
        "개념\n",
        "\n",
        "학습 중 손실(loss)·정확도(acc) 변화를 시각화하여 추적\n",
        "\n",
        "TensorBoard를 이용해 학습 과정을 실시간으로 모니터링 가능"
      ],
      "metadata": {
        "id": "k69FU0HImS3M"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y2xy85AImw8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.tensor([[1.,-1.], [1.,-1.]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0LP1txgYOj4",
        "outputId": "c408bbd4-508c-4301-dcb4-3a8d7fb3865a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1., -1.],\n",
              "        [ 1., -1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.tensor([[1,2], [3,4]]))\n",
        "print(torch.tensor([[1,2], [3,4]], device=\"cuda:0\"))\n",
        "print(torch.tensor([[1,2], [3,4]], dtype=torch.float64))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2kqN48_hHmb",
        "outputId": "431e3f08-779d-4e48-9700-e3f361d4dd7f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[1, 2],\n",
            "        [3, 4]], device='cuda:0')\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp=torch.tensor([[1,2], [3,4]])\n",
        "print(temp.numpy())\n",
        "\n",
        "temp=torch.tensor([[1,2], [3,4]], device=\"cuda:0\")\n",
        "print(temp.to(\"cpu\").numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R27ppQfwhJCW",
        "outputId": "d82aceec-7a5e-4faf-ec25-1b41e4b7035c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n",
            "[[1 2]\n",
            " [3 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp=torch.FloatTensor([1,2,3,4,5,6,7])\n",
        "print(temp[0], temp[1], temp[-1])\n",
        "print('------------------------')\n",
        "print(temp[2:5], temp[4:-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT3-PJdLhP1d",
        "outputId": "aa4a8f66-52bf-41da-b709-4643b2e2803c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.) tensor(2.) tensor(7.)\n",
            "------------------------\n",
            "tensor([3., 4., 5.]) tensor([5., 6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v=torch.tensor([1,2,3])\n",
        "w=torch.tensor([3,4,6])\n",
        "print(w-v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZsXVHKUh9DN",
        "outputId": "a9d02421-c6df-4041-c02e-11bef379ac99"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp=torch.tensor([\n",
        "    [1,2], [3,4]])\n",
        "\n",
        "print(temp.shape)\n",
        "print('---------------------')\n",
        "print(temp.view(4,1))\n",
        "print('---------------------')\n",
        "print(temp.view(-1))\n",
        "print('---------------------')\n",
        "print(temp.view(1,-1))\n",
        "print('---------------------')\n",
        "print(temp.view(-1,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pawlUPWhiAKp",
        "outputId": "b87ac7e1-c6f2-48b8-9a2c-e017789e136d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n",
            "---------------------\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n",
            "---------------------\n",
            "tensor([1, 2, 3, 4])\n",
            "---------------------\n",
            "tensor([[1, 2, 3, 4]])\n",
            "---------------------\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcpIJAHAiXSG",
        "outputId": "07406d88-a53e-4f73-ab1d-5bca8bfc12b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import pandas as pd\n",
        "import torch\n",
        "data=pd.read_csv('../class2.csv')\n",
        "\n",
        "x=torch.from_numpy(data['x'].values).unsqueeze(dim=1).float()\n",
        "y=torch.from_numpy(data['y'].values).unsqueeze(dim=1).float()\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "TuClNQbZiBWB",
        "outputId": "39053e0c-f4cc-4b7f-847d-73b490a30600"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport pandas as pd\\nimport torch\\ndata=pd.read_csv('../class2.csv')\\n\\nx=torch.from_numpy(data['x'].values).unsqueeze(dim=1).float()\\ny=torch.from_numpy(data['y'].values).unsqueeze(dim=1).float()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "    def __len__(self):\n",
        "    def __getitem__(self, index):\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KMZQTlgbiF_f",
        "outputId": "7c99d202-a698-46da-8b79-39b8b52c06f8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass CustomDataset(torch.utils.data.Dataset):\\n    def __init__(self):\\n    def __len__(self):\\n    def __getitem__(self, index):\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        self.label=pd.read_csv(csv_file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample=torch.tensor(self.label.iloc[idx, 0:3]).int()\n",
        "        label=torch.tensor(self.label.iloc[idx, 3]).int()\n",
        "        return sample, label\n",
        "\n",
        "tensor_dataset=CustomDataset('../covtype.csv')\n",
        "dataset=DataLoader(tensor_dataset, batch_size=4, shuffle=True)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "_py8-IDoilBn",
        "outputId": "a726c587-5da7-4ff9-ed06-96f9f0a47a5d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport pandas as pd\\nimport torch\\nfrom torch.utils.data import Dataset\\nfrom torch.utils.data import DataLoader\\n\\nclass CustomDataset(Dataset):\\n    def __init__(self, csv_file):\\n        self.label=pd.read_csv(csv_file)\\n\\n    def __len__(self):\\n        return len(self.label)\\n\\n    def __getitem__(self, idx):\\n        sample=torch.tensor(self.label.iloc[idx, 0:3]).int()\\n        label=torch.tensor(self.label.iloc[idx, 3]).int()\\n        return sample, label\\n\\ntensor_dataset=CustomDataset('../covtype.csv')\\ndataset=DataLoader(tensor_dataset, batch_size=4, shuffle=True)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "for i, data in enumerate(dataset, 0):\n",
        "    print(i, end='')\n",
        "    batch=data[0]\n",
        "    print(batch.size())\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6kxRruRLim-2",
        "outputId": "ad19c0e5-b50a-455b-a67f-f555694dc442"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor i, data in enumerate(dataset, 0):\\n    print(i, end='')\\n    batch=data[0]\\n    print(batch.size())\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxlP72MsipHx",
        "outputId": "1b72570b-f80c-40b5-a3cc-815e6f8b90cc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "mnist_transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (1.0,))\n",
        "])\n",
        "\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "import requests\n",
        "\n",
        "download_root='../chap02/data/MNIST_DATASET'\n",
        "\n",
        "train_dataset=MNIST(download_root, transform=mnist_transform, train=True,\n",
        "                    download=True)\n",
        "valid_dataset=MNIST(download_root, transform=mnist_transform, train=False,\n",
        "                    download=True)\n",
        "test_dataset=MNIST(download_root, transform=mnist_transform, train=False,\n",
        "                   download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc2NCD_OiqOA",
        "outputId": "28b5fc95-c57d-4687-905f-b907c73cfc3c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 20.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 561kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.81MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "model=nn.Linear(in_features=1, out_features=1, bias=True)"
      ],
      "metadata": {
        "id": "2H2yPuUwirhP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, inputs):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer=Linear(inputs, 1)\n",
        "        self.activation=Sigmoid()\n",
        "\n",
        "    def forward(self, X):\n",
        "        X=self.layer(X)\n",
        "        X=self.activation(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "c-j9Av0-is_K"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer1=nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        self.layer2=nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=30, kernel_size=5),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        self.layer3=nn.Sequential(\n",
        "            nn.Linear(in_features=30*5*5, out_features=10, bias=True),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.layer1(x)\n",
        "        x=self.layer2(x)\n",
        "        x=x.view(x.shape[0],-1)\n",
        "        x=self.layer3(x)\n",
        "        return x\n",
        "model=MLP()\n",
        "\n",
        "print(\"Printing children\\n-----------------------\")\n",
        "print(list(model.children()))\n",
        "print(\"\\n\\nPrinting Modules\\n-------------------------\")\n",
        "print(list(model.modules()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJkxStVMiuF5",
        "outputId": "4188ffc4-4814-4fd2-9b4b-9ecd068ac2fd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing children\n",
            "-----------------------\n",
            "[Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "), Sequential(\n",
            "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            ")]\n",
            "\n",
            "\n",
            "Printing Modules\n",
            "-------------------------\n",
            "[MLP(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Linear(in_features=750, out_features=10, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "), Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "), Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
            "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "), Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
            "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            "), Linear(in_features=750, out_features=10, bias=True), ReLU(inplace=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MLP(in_features=1, hidden_features=20, out_features=1):\n",
        "    hidden=nn.Linear(in_features=in_features, out_features=hidden_features,\n",
        "                     bias=True)\n",
        "    activation=nn.ReLU()\n",
        "    output=nn.Linear(in_features=hidden_features, out_features=out_features,\n",
        "                     bias=True)\n",
        "    net=nn.Sequential(hidden, activation, output)\n",
        "    return net"
      ],
      "metadata": {
        "id": "QxPa0CeCiwDg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from torch.optim import optimizer\n",
        "criterion=torch.nn.MSELoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler=torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
        "                                            lr_lambda=lambda epoch: 0.95**epoch)\n",
        "\n",
        "for epoch in range(1, 100+1):\n",
        "   for x, y in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "loss_fn(model(x), y).backward()\n",
        "optimizer.step()\n",
        "scheduler.step()\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "G-gWLONXix2-",
        "outputId": "79f00b1a-61db-4f50-90b3-423ccbe79d74"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom torch.optim import optimizer\\ncriterion=torch.nn.MSELoss()\\noptimizer=torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\\nscheduler=torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer,\\n                                            lr_lambda=lambda epoch: 0.95**epoch)\\n\\nfor epoch in range(1, 100+1):\\n   for x, y in dataloader:\\n        optimizer.zero_grad()\\nloss_fn(model(x), y).backward()\\noptimizer.step()\\nscheduler.step()\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "for epoch in range(100):\n",
        "   yhat=model(x_train)\n",
        "    loss=criterion(yhat, y_train)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "mCTI-xavi0WT",
        "outputId": "8b244bde-a8c4-4e37-c6aa-96397f556c37"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor epoch in range(100):\\n   yhat=model(x_train)\\n    loss=criterion(yhat, y_train)\\n    optimizer.zero_grad()\\n    loss.backward()\\n    optimizer.step()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE5WufN-i-Py",
        "outputId": "fc7540e0-e266-4aa0-e29e-bd91efc83883"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import torch\n",
        "import torchmetrics\n",
        "\n",
        "preds=torch.randn(10,5).softmax(dim=-1)\n",
        "target=torch.randint(5, (10,))\n",
        "\n",
        "acc=torchmetrics.functional.accuracy(preds, target)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "WIHh5DbtjABA",
        "outputId": "e911cd03-e882-4a97-b567-16faead9d5a7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport torch\\nimport torchmetrics\\n\\npreds=torch.randn(10,5).softmax(dim=-1)\\ntarget=torch.randint(5, (10,))\\n\\nacc=torchmetrics.functional.accuracy(preds, target)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import torch\n",
        "import torchmetrics\n",
        "metric=torchmetrics.Accuracy()\n",
        "\n",
        "n_batches=10\n",
        "for i in range(n_batches):\n",
        "  preds=torch.randn(10,5).softmax(dim=-1)\n",
        "  target=torch.randint(5, (10,))\n",
        "\n",
        "  acc=metric(preds, target)\n",
        "  print(f\"Accuracy on batch {i}: {acc}\")\n",
        "\n",
        "acc=metric.compute()\n",
        "print(f\"Accuracy on all data: {acc}\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "C7FGcOhwjC6O",
        "outputId": "0e8b13ef-6e10-4b7b-eb10-be57d207919e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport torch\\nimport torchmetrics\\nmetric=torchmetrics.Accuracy()\\n\\nn_batches=10\\nfor i in range(n_batches):\\n  preds=torch.randn(10,5).softmax(dim=-1)\\n  target=torch.randint(5, (10,))\\n\\n  acc=metric(preds, target)\\n  print(f\"Accuracy on batch {i}: {acc}\")\\n\\nacc=metric.compute()\\nprint(f\"Accuracy on all data: {acc}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKVwNKVbjEv6",
        "outputId": "5420ec4c-52b6-49ba-ba92-9031321878e8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "writer=SummaryWriter('../chap02/tensorboard')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    batch_loss=0.0\n",
        "\n",
        "for i, (x,y) in enumerate(dataloader):\n",
        "    x, y=x.to(device).float(), y.to(device).float()\n",
        "    outputs=model(x)\n",
        "    loss=criterion(outputs, y)\n",
        "    writer.add_scalar('Loss', loss, epoch)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "writer.close()\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "kC8qP2OAjG49",
        "outputId": "48fa92b8-b94a-4472-8b50-445771ab1f41"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport torch\\nfrom torch.utils.tensorboard import SummaryWriter\\n\\nwriter=SummaryWriter('../chap02/tensorboard')\\n\\nfor epoch in range(num_epochs):\\n    model.train()\\n    batch_loss=0.0\\n\\nfor i, (x,y) in enumerate(dataloader):\\n    x, y=x.to(device).float(), y.to(device).float()\\n    outputs=model(x)\\n    loss=criterion(outputs, y)\\n    writer.add_scalar('Loss', loss, epoch)\\n    optimizer.zero_grad()\\n    loss.backward()\\n    optimizer.step()\\n\\nwriter.close()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "tensorboard --logdir=../chap02/tensorboard --port=6006\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZkUEQf7jjqpm",
        "outputId": "759781b0-8d49-40ad-d2d2-773c7d18dcd8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntensorboard --logdir=../chap02/tensorboard --port=6006\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    valid_loss=0\n",
        "\n",
        "    for x, y in valid_dataloader:\n",
        "        outputs=model(x)\n",
        "        loss=F.cross_entropy(outputs, y.long().squeeze)\n",
        "        valid_loss+=float(loss)\n",
        "        y_hat+=[outputs]\n",
        "\n",
        "valid_loss=valid_loss/len(valid_loader)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nnI5qKGWjJkv",
        "outputId": "01e20acf-2a8d-462a-a164-7ab94c300713"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmodel.eval()\\nwith torch.no_grad():\\n    valid_loss=0\\n\\n    for x, y in valid_dataloader:\\n        outputs=model(x)\\n        loss=F.cross_entropy(outputs, y.long().squeeze)\\n        valid_loss+=float(loss)\\n        y_hat+=[outputs]\\n\\nvalid_loss=valid_loss/len(valid_loader)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}