{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwtJ0Xiua/xuUTad/IyDV9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinwooChoi/ESAA-OB/blob/main/9_29_ESAA_OB_%ED%95%84%EC%82%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "범위: <파이썬 머신러닝 완벽 가이드> 8장 p.509-534"
      ],
      "metadata": {
        "id": "z1f8wh93psEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "텍스트 분류 실습 - 20 뉴스그룹 분류\n",
        "- 목적: 학습한 모델로 새 문서의 카테고리 예측\n",
        "- 데이터: sklearn.datasets.fetch_20newsgroups(subset='all') → Bunch(keys: data, filenames, target_names, target, DESCR)\n",
        "- 모델 기본선: 로지스틱 회귀(나이브 베이스/SVM도 후보)\n",
        "\n",
        "텍스트 정규화\n",
        "- 불필요 메타정보(헤더/푸터 등) 제외 가능(subset/옵션 사용)\n",
        "- 토큰화·불용어 제거 등은 Vectorizer 옵션으로 처리(stop_words='english' 등)\n",
        "\n",
        "피처 벡터화 변환과 머신러닝 모델 학습/예측/평가\n",
        "- CountVectorizer: 단어 빈도 기반 BoW 희소행렬 생성\n",
        "- TfidfVectorizer: TF–IDF 가중치로 일반적으로 더 나은 분류 성능\n",
        "- 주의: 학습 데이터에만 fit(), 테스트는 transform()만 수행(데이터 누수 방지)\n",
        "- 예시 차원: (11314, 101631) 형태의 희소행렬\n",
        "\n",
        "[Output] Count 기반 베이스라인\n",
        "- 모델: LogisticRegression(solver='liblinear')\n",
        "- 테스트 정확도 ≈ 0.616\n",
        "\n",
        "TF–IDF\n",
        "- Count 대비 예측 성능 개선 경향\n",
        "- 벡터화 성능 영향 요소: stop_words, ngram_range, max_df 등 하이퍼파라미터\n",
        "\n",
        "GridSearchCV\n",
        "- 목적: Vectorizer(예: ngram_range, max_df)와 분류기(예: C) 최적화\n",
        "- 예시: C∈{0.01,0.1,1,5,10} 교차검증 3-fold → 최적 C=10\n",
        "- TF–IDF + 최적 C 적용 시 테스트 정확도 ≈ 0.704\n",
        "\n",
        "사이킷런 파이프라인(Pipeline) 사용 및 GridSearchCV와의 결합\n",
        "- 구성 예: [('tfidf_vect', TfidfVectorizer(stop_words='english')), ('lr_clf', LogisticRegression())]\n",
        "- 장점: 전처리→벡터화→학습/예측 일관 실행, 코드 단순·누수 방지\n",
        "- 파라미터 그리드 키 규칙: 단계이름__하이퍼파라미터 (예: 'tfidf_vect__ngram_range', 'lr_clf__C')\n",
        "- 주의: 파이프라인×그리드 조합 크기×CV 폴드 수 → 튜닝 시간 급증\n",
        "\n",
        "추가 권장 모델\n",
        "- LinearSVC(선형 SVM), MultinomialNB(나이브 베이즈) 등 텍스트 분류에 강함\n",
        "\n"
      ],
      "metadata": {
        "id": "-27_1jWRtn98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "감성 분석(Sentiment Analysis)\n",
        "\n",
        "- 문서의 주관적 감정·의견·기분을 파악하는 분석 방법  \n",
        "- 소셜 미디어, 여론조사, 리뷰 등 다양한 분야에서 활용  \n",
        "- 문맥과 단어를 기반으로 긍정/부정 감정 지수 계산  \n",
        "\n",
        "감성 분석의 종류\n",
        "\n",
        "- 지도학습(Supervised Learning)\n",
        "  - 라벨이 있는 학습 데이터를 통해 감성 분류 모델 학습  \n",
        "  - 새로운 데이터의 감정을 예측  \n",
        "\n",
        "- 비지도학습(Unsupervised Learning)\n",
        "  - Lexicon(감성 사전)을 이용  \n",
        "  - 단어의 긍·부정 점수를 활용해 문서의 감정 결정  \n",
        "\n",
        "\n",
        "비지도학습 기반 감성 분석 소개\n",
        "\n",
        "- Lexicon 기반으로 감정 분류 수행  \n",
        "- 감정 사전(Lexicon): 단어별 감정 점수(긍정/부정) 보유  \n",
        "- 대표 감정 사전: NLTK 패키지  \n",
        "\n",
        "\n",
        "\n",
        "WordNet 개요\n",
        "\n",
        "- 단어의 의미(시맨틱)와 관계를 정의한 영어 어휘 사전  \n",
        "- 단어 간 동의어(Synonym), 유의어(Synset) 관계 제공  \n",
        "- 시맨틱(Semantic): 문맥상의 의미를 고려  \n",
        "\n",
        "Synset 개념\n",
        "\n",
        "- 동일 의미를 가지는 단어들의 집합  \n",
        "- Synset(‘present, n.01’) → 명사, 시간 의미  \n",
        "- Synset(‘present, n.02’) → 명사, 선물 의미  \n",
        "- WordNet은 Synset 간 유사도(path_similarity) 계산 가능  \n",
        "\n",
        " SentiWordNet\n",
        "\n",
        "- WordNet의 Synset에 감정 점수를 부여한 확장 버전  \n",
        "- 감정 점수: 긍정 / 부정 / 객관  \n",
        "- 각 단어의 감정 비율을 수치로 표현  \n",
        "\n",
        "VADER\n",
        "\n",
        "- 소셜 미디어용 감성 분석 Lexicon  \n",
        "- SentimentIntensityAnalyzer 사용  \n",
        "- 간단한 코드로 감정 분석 수행 가능  \n",
        "- 긍정/부정/중립/복합 점수 제공  \n",
        "\n",
        "Pattern\n",
        "\n",
        "- 예측 성능이 높고 빠른 감성 분석 패키지  \n",
        "- 문장 내 감정 패턴을 기반으로 점수 계산  \n",
        "\n",
        "SentiWordNet을 이용한 감성 분석\n",
        "\n",
        "- WordNet 기반 Synset을 활용  \n",
        "- SentiSynset: 감정 점수(긍정/부정/객관) 포함  \n",
        "- POS(품사), Definition(정의), Lemma(표제어) 정보 포함  \n",
        "\n",
        "SentiWordNet을 이용한 영화평 감성 분석 단계\n",
        "\n",
        "1. 문서를 문장 단위로 분해  \n",
        "2. 문장을 단어 단위로 토크나이즈 및 품사 태깅  \n",
        "3. 품사 태그 기반 Synset 및 SentiSynset 생성  \n",
        "4. 감정 점수를 합산하여 최종 긍정/부정 결정  \n",
        "\n",
        "VADER를 이용한 감성 분석\n",
        "\n",
        "- NLTK 기반 Lexicon  \n",
        "- 소셜 미디어 감정 분석에 적합  \n",
        "- SentimentIntensityAnalyzer 클래스로 감정 점수 계산  \n",
        "- 긍정/부정/중립/복합 점수 출력\n"
      ],
      "metadata": {
        "id": "h21L4iMxuzDN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wisnl5pPoxiR"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "news_data=fetch_20newsgroups(subset='all', random_state=156)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_data.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utcnN-G1oywo",
        "outputId": "d1f8fe45-054b-49b3-d086-1b0a55d8989c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "print('target 클래스의 값과 분포도 \\n', pd.Series(news_data.target).value_counts().sort_index())\n",
        "print('target 클래스의 이름들 \\n', news_data.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQt_hPKRoz0U",
        "outputId": "d4ee9acf-3bbb-43be-9381-1961a4ac4f72"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 클래스의 값과 분포도 \n",
            " 0     799\n",
            "1     973\n",
            "2     985\n",
            "3     982\n",
            "4     963\n",
            "5     988\n",
            "6     975\n",
            "7     990\n",
            "8     996\n",
            "9     994\n",
            "10    999\n",
            "11    991\n",
            "12    984\n",
            "13    990\n",
            "14    987\n",
            "15    997\n",
            "16    910\n",
            "17    940\n",
            "18    775\n",
            "19    628\n",
            "Name: count, dtype: int64\n",
            "target 클래스의 이름들 \n",
            " ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_data.data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEAuH1Qco1z4",
        "outputId": "58e1372f-3879-45d2-9bb4-bc298233e126"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: egreen@east.sun.com (Ed Green - Pixel Cruncher)\n",
            "Subject: Re: Observation re: helmets\n",
            "Organization: Sun Microsystems, RTP, NC\n",
            "Lines: 21\n",
            "Distribution: world\n",
            "Reply-To: egreen@east.sun.com\n",
            "NNTP-Posting-Host: laser.east.sun.com\n",
            "\n",
            "In article 211353@mavenry.altcit.eskimo.com, maven@mavenry.altcit.eskimo.com (Norman Hamer) writes:\n",
            "> \n",
            "> The question for the day is re: passenger helmets, if you don't know for \n",
            ">certain who's gonna ride with you (like say you meet them at a .... church \n",
            ">meeting, yeah, that's the ticket)... What are some guidelines? Should I just \n",
            ">pick up another shoei in my size to have a backup helmet (XL), or should I \n",
            ">maybe get an inexpensive one of a smaller size to accomodate my likely \n",
            ">passenger? \n",
            "\n",
            "If your primary concern is protecting the passenger in the event of a\n",
            "crash, have him or her fitted for a helmet that is their size.  If your\n",
            "primary concern is complying with stupid helmet laws, carry a real big\n",
            "spare (you can put a big or small head in a big helmet, but not in a\n",
            "small one).\n",
            "\n",
            "---\n",
            "Ed Green, former Ninjaite |I was drinking last night with a biker,\n",
            "  Ed.Green@East.Sun.COM   |and I showed him a picture of you.  I said,\n",
            "DoD #0111  (919)460-8302  |\"Go on, get to know her, you'll like her!\"\n",
            " (The Grateful Dead) -->  |It seemed like the least I could do...\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "#subset='train'으로 학습용 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
        "train_news=fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'),\n",
        "                              random_state=156)\n",
        "X_train=train_news.data\n",
        "y_train=train_news.target\n",
        "\n",
        "#subset='test'으로 테스트 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
        "test_news=fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'),\n",
        "                             random_state=156)\n",
        "X_test=test_news.data\n",
        "y_test=test_news.target\n",
        "print('학습 데이터 크기 {0}, 테스트 데이터 크기 {1}'.format(len(train_news.data),\n",
        "                                             len(test_news.data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVxpEwUQo3vY",
        "outputId": "d8c5a5d9-f056-486d-e730-d7a61bfdea7f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 크기 11314, 테스트 데이터 크기 7532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#Count Vectorization으로 피처 벡터화 변환 수행\n",
        "cnt_vect=CountVectorizer()\n",
        "cnt_vect.fit(X_train)\n",
        "X_train_cnt_vect=cnt_vect.transform(X_train)\n",
        "\n",
        "#학습 데이터로 fit()된 CountVectorizer를 이용해 테스트 데이터를 피처 벡터화 변환 수행\n",
        "X_test_cnt_vect=cnt_vect.transform(X_test)\n",
        "\n",
        "print('학습 데이터 텍스트의 CountVectorizer Shape:', X_train_cnt_vect.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LewPOZPo5_V",
        "outputId": "ff8d3795-943d-4967-ff3b-a6fdc4b2a07d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 텍스트의 CountVectorizer Shape: (11314, 101631)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#LogisticRegression을 이용하여 학습/예측/평가 수행\n",
        "lr_clf=LogisticRegression(solver='liblinear')\n",
        "lr_clf.fit(X_train_cnt_vect, y_train)\n",
        "pred=lr_clf.predict(X_test_cnt_vect)\n",
        "print('CountVectorized Logistic Regression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test,pred)))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNumHo4Qo7rI",
        "outputId": "c91ece2e-db45-43a3-8ec7-e01c53b8e05d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorized Logistic Regression의 예측 정확도는 0.617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#TF-IDF 벡터화를 적용해 학습 데이터 세트과 테스트 데이터 세트 변환\n",
        "tfidf_vect=TfidfVectorizer()\n",
        "tfidf_vect.fit(X_train)\n",
        "X_train_tfidf_vect=tfidf_vect.transform(X_train)\n",
        "X_test_tfidf_vect=tfidf_vect.transform(X_test)\n",
        "\n",
        "#LogisticRegression을 이용해 학습/예측/평가 수행\n",
        "lr_clf=LogisticRegression(solver='liblinear')\n",
        "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
        "pred=lr_clf.predict(X_test_tfidf_vect)\n",
        "print('TF-IDF Logistic Regression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgc78uc8o9RS",
        "outputId": "4ff5e860-4083-4936-89dd-2d202c3a022f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Logistic Regression의 예측 정확도는 0.678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stop words 필터링을 추가하고 ngram을 기본(1,1)에서 (1,2)로 변경해 피처 벡터화 적용\n",
        "tfidf_vect=TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300)\n",
        "tfidf_vect.fit(X_train)\n",
        "X_train_tfidf_vect=tfidf_vect.transform(X_train)\n",
        "X_test_tfidf_vect=tfidf_vect.transform(X_test)\n",
        "\n",
        "lr_clf=LogisticRegression(solver='liblinear')\n",
        "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
        "pred=lr_clf.predict(X_test_tfidf_vect)\n",
        "print('TF-IDF Vectorized Logistic Regression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQNZsLVfo_gO",
        "outputId": "a70dd7fa-3047-4049-fac4-6712a5fe537b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Vectorized Logistic Regression의 예측 정확도는 0.690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#최적 C 값 도출 튜닝 수행. CV는 3 폴드 세트로 설정\n",
        "params={'C':[0.01, 0.1, 1, 5, 10]}\n",
        "grid_cv_lr=GridSearchCV(lr_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
        "grid_cv_lr.fit(X_train_tfidf_vect, y_train)\n",
        "print('Logistic Regression best C parameter:', grid_cv_lr.best_params_)\n",
        "\n",
        "#최적 C 값으로 학습된 grid_cv로 예측 및 정확도 평가\n",
        "pred=grid_cv_lr.predict(X_test_tfidf_vect)\n",
        "print('TF-IDF Vectorized Logistic Regression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqkeYdnapBDK",
        "outputId": "ffbfe59c-8233-4823-ca70-1a98a5bc579f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "Logistic Regression best C parameter: {'C': 10}\n",
            "TF-IDF Vectorized Logistic Regression의 예측 정확도는 0.704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline=Pipeline([('tfidf_vect', TfidfVectorizer(stop_words='english')),\n",
        "    ('lr_clf', LogisticRegression(random_state=156))])"
      ],
      "metadata": {
        "id": "ZBfYRswXpCf7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#TfidfVectorizer 객체를 tfidf_vect로, LogisticRegression 객체를 lr_clf로 생성하는 Pipeline 생성\n",
        "pipeline=Pipeline([\n",
        "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300)),\n",
        "    ('lr_clf', LogisticRegression(solver='liblinear', C=10))\n",
        "])\n",
        "\n",
        "#별도의 TfidfVectorizer 객체의 fit(), transform()과 LogisticRegression의 fit(), predict()가 필요 없음\n",
        "#pipeline의 fit()과 predict()만으로 한꺼번에 피처 벡터화와 ML 학습/예측이 가능\n",
        "pipeline.fit(X_train, y_train)\n",
        "pred=pipeline.predict(X_test)\n",
        "print('Pipeline을 통한 Logistic Regression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTLtamlYpD0Q",
        "outputId": "74998b84-3517-4447-ac0e-ed33400bae5a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline을 통한 Logistic Regression의 예측 정확도는 0.704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline=Pipeline([\n",
        "    ('tfidf_vect', TfidfVectorizer(stop_words='english')),\n",
        "    ('lr_clf', LogisticRegression())\n",
        "])\n",
        "\n",
        "#Pipeline에 기술된 각각의 객체 변수에 언더바(_) 2개를 연달아 붙여 GridSearchCV에 사용될\n",
        "#파라미터/하이퍼 파라미터 이름과 값을 설정\n",
        "params={'tfidf_vect__ngram_range': [(1,1), (1,2), (1,3)],\n",
        "           'tfidf_vect__max_df': [100, 300, 700],\n",
        "           'lr_clf__C': [1,5,10]\n",
        "}\n",
        "\n",
        "#GridSearchCV의 생성자에 Estimator가 아닌 Pipeline 객체 입력\n",
        "grid_cv_pipe=GridSearchCV(pipeline, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
        "grid_cv_pipe.fit(X_train, y_train)\n",
        "print(grid_cv_pipe.best_params_, grid_cv_pipe.best_score_)\n",
        "\n",
        "pred=grid_cv_pipe.predict(X_test)\n",
        "print('Pipeline을 통한 Logistic Regression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test, pred)))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK7yZ37gpFQw",
        "outputId": "4ca33336-caea-4b6c-c6ae-b5a93103b82c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "review_df=pd.read_csv('labeledTrainData.tsv', header=0, sep=\"\\t\", quoting=3)\n",
        "review_df.head(3)"
      ],
      "metadata": {
        "id": "1wOohWJzpHpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(review_df['review'][0])"
      ],
      "metadata": {
        "id": "a-QjPUKcpJVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# html 태그는 replace 함수로 공백으로 변환\n",
        "review_df['review']=review_df['review'].str.replace('', ' ')\n",
        "\n",
        "#파이썬의 정규 표현식 모듈인 re를 이용해 영어 문자열이 아닌 문자는 모두 공백으로 변환\n",
        "review_df['review']=review_df['review'].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))"
      ],
      "metadata": {
        "id": "jc5YdX_tpKoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class_df=review_df['sentiment']\n",
        "feature_df=review_df.drop(['id', 'sentiment'], axis=1, inplace=False)\n",
        "X_train, X_test, y_train, y_test=train_test_split(feature_df, class_df, test_size=0.3,\n",
        "                                                random_state=156)\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "y_DZQ1w3pM-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "#스톱 워드는 English, ngram은 (1,2)로 설정해 CountVectorization 수행\n",
        "#LogisticRegression의 C는 10으로 설정\n",
        "pipeline=Pipeline([\n",
        "    ('cnt_vect', CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
        "    ('lr_clf', LogisticRegression(solver='liblinear', C=10))])\n",
        "\n",
        "#Pipeline 객체를 이용해 fit(), predict()로 학습/예측 수행. predict_proba()는 roc_auc 때문에 수행\n",
        "pipeline.fit(X_train['review'], y_train)\n",
        "pred=pipeline.predict(X_test['review'])\n",
        "pred_probs=pipeline.predict_proba(X_test['review'])[:,1]\n",
        "\n",
        "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test,pred),\n",
        "                                                 roc_auc_score(y_test, pred_probs)))"
      ],
      "metadata": {
        "id": "8SiDrC5lpOS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#스톱 워드는 english, filtering, ngram은 (1,2)로 설정해 TF-IDF 벡터화 수행\n",
        "#LogisticRegression의 C는 10으로 설정\n",
        "pipeline=Pipeline([\n",
        "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1,2))),\n",
        "    ('lr_clf', LogisticRegression(solver='liblinear', C=10))])\n",
        "\n",
        "pipeline.fit(X_train['review'], y_train)\n",
        "pred=pipeline.predict(X_test['review'])\n",
        "pred_probs=pipeline.predict_proba(X_test['review'])[:,1]\n",
        "\n",
        "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test,pred),\n",
        "                                                 roc_auc_score(y_test, pred_probs)))"
      ],
      "metadata": {
        "id": "cmVosMoFpP8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "xsWrRhVupRvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "term='present'\n",
        "\n",
        "#'present'라는 단어로 wordnet의 synsets 생성\n",
        "synsets=wn.synsets(term)\n",
        "print('synsets() 반환 type:', type(synsets))\n",
        "print('synsets() 반환 값 개수:', len(synsets))\n",
        "print('synsets() 반환 값:', synsets)"
      ],
      "metadata": {
        "id": "Q7rP8yfQpTEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for synset in synsets:\n",
        "    print('##### Synset name:', synset.name(), '#####')\n",
        "    print('POS:', synset.lexname())\n",
        "    print('Definition:', synset.definition())\n",
        "    print('Lemmas:', synset.lemma_names())"
      ],
      "metadata": {
        "id": "wr7AhayApVL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#synset 객체를 단어 별로 생성\n",
        "tree=wn.synset('tree.n.01')\n",
        "lion=wn.synset('lion.n.01')\n",
        "tiger=wn.synset('tiger.n.02')\n",
        "cat=wn.synset('cat.n.01')\n",
        "dog=wn.synset('dog.n.01')\n",
        "\n",
        "entities=[tree, lion, tiger, cat, dog]\n",
        "similarities=[]\n",
        "entity_names=[entity.name().split('.')[0] for entity in entities]\n",
        "\n",
        "#단어 별 synset을 반복하면서 다른 단어의 synset과 유사도를 측정\n",
        "for entity in entities:\n",
        "    similarity=[round(entity.path_similarity(compared_entity), 2)\n",
        "                for compared_entity in entities]\n",
        "    similarities.append(similarity)\n",
        "\n",
        "#개별 단어 별 synset과 다른 단어의 synset과의 유사도를 DataFrame 형태로 저장\n",
        "similarity_df=pd.DataFrame(similarities, columns=entity_names, index=entity_names)\n",
        "similarity_df"
      ],
      "metadata": {
        "id": "XOYCHmyMpWfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "\n",
        "senti_synsets=list(swn.senti_synsets('slow'))\n",
        "print('senti_synsets() 반환 type:', type(senti_synsets))\n",
        "print('senti_synsets() 반환 값 개수:', len(senti_synsets))\n",
        "print('senti_synsets() 반환 값:', senti_synsets)"
      ],
      "metadata": {
        "id": "_6zrtW37pYLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "\n",
        "father=swn.senti_synset('father.n.01')\n",
        "print('father 긍정감성 지수:', father.pos_score())\n",
        "print('father 부정감성 지수:', father.neg_score())\n",
        "print('father 객관성 지수:', father.obj_score())\n",
        "print('\\n')\n",
        "fabulous=swn.senti_synset('fabulous.a.01')\n",
        "print('fabulous 긍정감성 지수:', fabulous.pos_score())\n",
        "print('fabulous 부정감성 지수:', fabulous.neg_score())"
      ],
      "metadata": {
        "id": "DLY-_Sa8pZXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "#간단한 NTLK PennTreebank Tag를 기반으로 WordNet 기반의 품사 Tag로 변환\n",
        "def penn_to_wn(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wn.ADJ\n",
        "    elif tag.startswith('N'):\n",
        "        return wn.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wn.ADV\n",
        "    elif tag.startswith('V'):\n",
        "        return wn.VERB\n",
        ""
      ],
      "metadata": {
        "id": "wJooRElwpbSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
        "\n",
        "def swn_polarity(text):\n",
        "    #감성 지수 초기화\n",
        "    sentiment=0.0\n",
        "    tokens_count=0\n",
        "\n",
        "    lemmatizer=WordNetLemmatizer()\n",
        "    raw_sentences=sent_tokenize(text)\n",
        "    #분해된 문장 별로 단어 토큰 -> 품사 태깅 후에 SentiSynset 생성 -> 감성 지수 합산\n",
        "    for raw_sentence in raw_sentences:\n",
        "        #NTLK 기반의 품사 태깅 문장 추출\n",
        "        tagged_sentence=pos_tag(word_tokenize(raw_sentence))\n",
        "        for word, tag in tagged_sentence:\n",
        "            #WordNet 기반 품사 태깅과 어근 추출\n",
        "            wn_tag=penn_to_wn(tag)\n",
        "            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
        "                continue\n",
        "            lemma=lemmatizer.lemmatize(word, pos=wn_tag)\n",
        "            if not lemma:\n",
        "                continue\n",
        "            #어근을 추출한 단어와 WordNet 기반 품사 태깅을 입력해 Synset 객체를 생성\n",
        "            synsets=wn.synsets(lemma, pos=wn_tag)\n",
        "            if not synsets:\n",
        "                continue\n",
        "            #sentiwordnet의 감성 단어 분석으로 감성 synset 추출\n",
        "            #모든 단어에 대해 긍정 감성 지수는 +로 부정 감성 지수는 -로 합산해 감성 지수 계산\n",
        "            synset=synsets[0]\n",
        "            swn_synset=swn.senti_synset(synset.name())\n",
        "            sentiment+=(swn_synset.pos_score()-swn_synset.neg_score())\n",
        "            tokens_count+=1\n",
        "\n",
        "    if not tokens_count:\n",
        "        return 0\n",
        "\n",
        "    #총 score가 0 이상일 경우 긍정(Positive) 1, 그렇지 않을 경우 부정(Negative) 0 반환\n",
        "    if sentiment >=0:\n",
        "        return 1\n",
        "\n",
        "    return 0"
      ],
      "metadata": {
        "id": "ObLCJhP1pcxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df['preds']=review_df['review'].apply(lambda x: swn_polarity(x))\n",
        "y_target=review_df['sentiment'].values\n",
        "preds=review_df['preds'].values"
      ],
      "metadata": {
        "id": "K0Qfq_27pjII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
        "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "print(confusion_matrix(y_target, preds))\n",
        "print(\"정확도:\", np.round(accuracy_score(y_target, preds), 4))\n",
        "print(\"정밀도:\", np.round(precision_score(y_target, preds), 4))\n",
        "print(\"재현율:\", np.round(recall_score(y_target, preds), 4))"
      ],
      "metadata": {
        "id": "3eApUuC1plri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "senti_analyzer=SentimentIntensityAnalyzer()\n",
        "senti_scores=senti_analyzer.polarity_scores(review_df['review'][0])\n",
        "print(senti_scores)"
      ],
      "metadata": {
        "id": "dwPQDroJpnFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vader_polarity(review,threshold=0.1):\n",
        "    analyzer=SentimentIntensityAnalyzer()\n",
        "    scores=analyzer.polarity_scores(review)\n",
        "\n",
        "    #compound 값에 기반해 threshold 입력값보다 크면 1, 그렇지 않으면 0을 반환\n",
        "    agg_score=scores['compound']\n",
        "    final_sentiment=1 if agg_score>=threshold else 0\n",
        "    return final_sentiment\n",
        "\n",
        "#apply lambda 식을 이용해 레코드 별로 vader_polarity()를 수행하고 결과를 'vader_preds'에 저장\n",
        "review_df['vader_preds']=review_df['review'].apply(lambda x:vader_polarity(x, 0.1))\n",
        "y_target=review_df['sentiment'].values\n",
        "vader_preds=review_df['vader_preds'].values\n",
        "\n",
        "print(confusion_matrix(y_target, vader_preds))\n",
        "print(\"정확도:\", np.round(accuracy_score(y_target, vader_preds), 4))\n",
        "print(\"정밀도:\", np.round(precision_score(y_target, vader_preds), 4))\n",
        "print(\"재현율:\", np.round(recall_score(y_target, vader_preds), 4))"
      ],
      "metadata": {
        "id": "X1hnzswMpoi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fB4mq4dEpqAR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}